{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq9wIGjSXVRi",
        "outputId": "eedc703d-870a-4975-8471-ef4ca3988198"
      },
      "id": "Oq9wIGjSXVRi",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NepaliWord2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUjIjrozVcnG",
        "outputId": "f52dbe35-7de9-41be-a515-e00813a7e063"
      },
      "id": "xUjIjrozVcnG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NepaliWord2vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27f0f05",
      "metadata": {
        "id": "b27f0f05"
      },
      "source": [
        "## Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2923ef4f",
      "metadata": {
        "id": "2923ef4f"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import time\n",
        "import re\n",
        "import snowballstemmer\n",
        "import gensim\n",
        "\n",
        "import setting as cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c457b94",
      "metadata": {
        "id": "8c457b94"
      },
      "source": [
        "## Reading the File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "200d7177",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "200d7177",
        "outputId": "e7131467-fe0d-40ff-ffc9-1f124358d334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading the file .......\n",
            "Total number of lines in text file 5891518\n",
            "Time required to read the file 68.18159049600001\n"
          ]
        }
      ],
      "source": [
        "start = time.process_time() \n",
        "print(\"Reading the file .......\")\n",
        "f = open(cfg.raw_text_files , encoding= 'utf-8' , buffering= 10000)\n",
        "lines = f.read().strip().split(u\"।\")\n",
        "sentences = [sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in lines]\n",
        "# f.close()\n",
        "print(f\"Total number of lines in text file {len(sentences)}\")\n",
        "print(f\"Time required to read the file {time.process_time() - start}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "46d1ec92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46d1ec92",
        "outputId": "3bc355fa-0dad-43f9-abfb-94621d674872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE FOR 0.0 LAKHS LINES\n",
            "DONE FOR 1.0 LAKHS LINES\n",
            "DONE FOR 2.0 LAKHS LINES\n",
            "DONE FOR 3.0 LAKHS LINES\n",
            "DONE FOR 4.0 LAKHS LINES\n",
            "DONE FOR 5.0 LAKHS LINES\n",
            "DONE FOR 6.0 LAKHS LINES\n",
            "DONE FOR 7.0 LAKHS LINES\n",
            "DONE FOR 8.0 LAKHS LINES\n",
            "DONE FOR 9.0 LAKHS LINES\n",
            "DONE FOR 10.0 LAKHS LINES\n",
            "DONE FOR 11.0 LAKHS LINES\n",
            "DONE FOR 12.0 LAKHS LINES\n",
            "DONE FOR 13.0 LAKHS LINES\n",
            "DONE FOR 14.0 LAKHS LINES\n",
            "DONE FOR 15.0 LAKHS LINES\n",
            "DONE FOR 16.0 LAKHS LINES\n",
            "DONE FOR 17.0 LAKHS LINES\n",
            "DONE FOR 18.0 LAKHS LINES\n",
            "DONE FOR 19.0 LAKHS LINES\n"
          ]
        }
      ],
      "source": [
        "mainlist = list()\n",
        "\n",
        "class Main_Data_list:\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.stop_word_list = []\n",
        "        self.mainlist = []\n",
        "        \n",
        "        a_file = open('input/stopwords/stopwords.txt', \"r\" ,encoding= 'utf-8')\n",
        "        for line in a_file:\n",
        "            stripped_line = line.strip()\n",
        "            self.stop_word_list.append(stripped_line)\n",
        "        a_file.close()\n",
        "        \n",
        "        self.stemmer = snowballstemmer.NepaliStemmer()\n",
        "        \n",
        "        \n",
        "    def simple_tokenizer(self,text) -> list:\n",
        "        \n",
        "        line = re.sub('[।]',\"\", text)\n",
        "        \n",
        "        devanagari_range = r'[\\u0900-\\u097F\\\\]'\n",
        "        def getDevanagariCharCount(token):\n",
        "            return len(list(filter(lambda char: re.match(devanagari_range, char), (char for char in token))))\n",
        "        def isDevanagari(token):\n",
        "            return True if getDevanagariCharCount(token) >= len(token)/2 else False \n",
        "\n",
        "        tokens = list(filter(lambda t: isDevanagari(t), line.split(\" \")))\n",
        "        return tokens\n",
        "\n",
        "    def get(self):\n",
        "        for i,line in enumerate(self.dataset[0:2000000]):\n",
        "            \n",
        "            wordsList = self.simple_tokenizer(line)\n",
        "            words = [w for w in wordsList if not w in self.stop_word_list]\n",
        "            words  = self.stemmer.stemWords(words)\n",
        "            if len(words) > 3:\n",
        "                self.mainlist.append(words)\n",
        "            if i % 100000 == 0:\n",
        "                print(f\"DONE FOR {i/100000} LAKHS LINES\")\n",
        "        return self.mainlist\n",
        "                \n",
        "final = Main_Data_list(sentences)\n",
        "mainlist = final.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "XynKhXuVb89K"
      },
      "id": "XynKhXuVb89K"
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "    window=  5,\n",
        "    min_count=2,\n",
        "    workers= 4,\n",
        "    size = 200,\n",
        ")\n",
        "\n",
        "model.build_vocab(mainlist, progress_per=1000 )\n",
        "\n",
        "model.train(mainlist, total_examples= model.corpus_count, epochs= model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tFA9a_6cANB",
        "outputId": "9cc93c92-5db3-430f-ae7d-ee099540e8c5"
      },
      "id": "6tFA9a_6cANB",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103822451, 122202960)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "ndgu084NdjS-"
      },
      "id": "ndgu084NdjS-"
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('जमल')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzPq6m4-cjKn",
        "outputId": "3e22bef6-1968-41f1-e06f-f854751c7c4a"
      },
      "id": "OzPq6m4-cjKn",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('पुतलीसडक', 0.8554033637046814),\n",
              " ('बानेश्वर', 0.8238137364387512),\n",
              " ('बागबजार', 0.8135662078857422),\n",
              " ('मैतीदेवी', 0.7989574074745178),\n",
              " ('गोंगबु', 0.7972407937049866),\n",
              " ('कलं', 0.7865052223205566),\n",
              " ('त्रिपुरेश्वर', 0.785507321357727),\n",
              " ('लैनचौर', 0.7765045166015625),\n",
              " ('तीनकु', 0.776380717754364),\n",
              " ('लाजिम्पाट', 0.7671419382095337)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('काठमाडौं')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wboE432cHTx",
        "outputId": "8e51b156-5a9b-4683-aa45-be44ee1aac2a"
      },
      "id": "5wboE432cHTx",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('काठमाडांै', 0.6255369186401367),\n",
              " ('काठमाडौ', 0.6137765645980835),\n",
              " ('काठमाडाैं', 0.5868496894836426),\n",
              " ('पोखरा', 0.5453355312347412),\n",
              " ('ललितपुर', 0.5321687459945679),\n",
              " ('भलामस्थित', 0.5107089281082153),\n",
              " ('स्वात्त', 0.5079240798950195),\n",
              " ('विराटनगर', 0.5032570362091064),\n",
              " ('काठमाडौं\\nकाठमाडौँ', 0.49517786502838135),\n",
              " ('भरतपुर', 0.4644666910171509)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('सुनिल')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQwhdOtwd_0Y",
        "outputId": "a0f42a5e-7879-45b9-e968-342ec3a64029"
      },
      "id": "BQwhdOtwd_0Y",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('सुनील', 0.8596311211585999),\n",
              " ('मनिष', 0.7828516364097595),\n",
              " ('बिक्रम', 0.782561182975769),\n",
              " ('प्रदिप', 0.7773913145065308),\n",
              " ('सुरज', 0.7743733525276184),\n",
              " ('समिर', 0.7712180614471436),\n",
              " ('धिरज', 0.7703405618667603),\n",
              " ('रवि', 0.766444206237793),\n",
              " ('दिपेश', 0.7663419246673584),\n",
              " ('सुशिल', 0.7656646966934204)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"nepaliW2V_5Million.model\")"
      ],
      "metadata": {
        "id": "DxBnp-ureM5r"
      },
      "id": "DxBnp-ureM5r",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mjsQRbJkerKv"
      },
      "id": "mjsQRbJkerKv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "nepali-word2vec.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}